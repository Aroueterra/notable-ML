{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CTC PREDICT for frozen model\n",
    "#import tensorflow.compat.v1 as tf_v1\n",
    "import tensorflow.compat.v1 as tf_v1\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.disable_eager_execution()\n",
    "tf_v1.compat.v1.disable_eager_execution()\n",
    "import simpleaudio as sa\n",
    "import numpy as np\n",
    "from midi.player import *\n",
    "\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import ctc_utils\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_pb(path_to_pb):\n",
    "    print(\"load graph\")\n",
    "    with tf_v1.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf_v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf_v1.Graph().as_default() as graph:\n",
    "        tf_v1.import_graph_def(graph_def, name='')\n",
    "        return graph\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Decode a music score image with a trained model (CTC).')\n",
    "parser.add_argument('-image',  dest='image', type=str, required=True, help='Path to the input image.')\n",
    "parser.add_argument('-model', dest='model', type=str, required=True, help='Path to the trained model.')\n",
    "parser.add_argument('-vocabulary', dest='voc_file', type=str, required=True, help='Path to the vocabulary file.')\n",
    "args = parser.parse_args()\n",
    "\n",
    "tf_v1.reset_default_graph()\n",
    "sess = tf_v1.InteractiveSession()\n",
    "eta_path = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/frozen_model.pb'\n",
    "# Read the dictionary\n",
    "dict_file = open(\"Data/vocabulary_semantic.txt\",'r')\n",
    "dict_list = dict_file.read().splitlines()\n",
    "int2word = dict()\n",
    "for word in dict_list:\n",
    "    word_idx = len(int2word)\n",
    "    int2word[word_idx] = word\n",
    "dict_file.close()\n",
    "\n",
    "\n",
    "print(\"load graph\")\n",
    "\n",
    "graph = load_pb(eta_path)    \n",
    "\n",
    "input = graph.get_tensor_by_name(\"model_input:0\")\n",
    "seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
    "rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "height_tensor = graph.get_tensor_by_name(\"input_height:0\")\n",
    "width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")\n",
    "logits = tf_v1.get_collection(\"logits\")[0]\n",
    "\n",
    "# Constants that are saved inside the model itself\n",
    "WIDTH_REDUCTION, HEIGHT = sess.run([width_reduction_tensor, height_tensor])\n",
    "\n",
    "decoded, _ = tf_v1.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "image = cv2.imread(\"Data/Example/000051652-1_2_1.png\",0)\n",
    "image = ctc_utils.resize(image, HEIGHT)\n",
    "image = ctc_utils.normalize(image)\n",
    "image = np.asarray(image).reshape(1,image.shape[0],-1,1)\n",
    "\n",
    "seq_lengths = [ image.shape[2] / WIDTH_REDUCTION ]\n",
    "\n",
    "prediction = sess.run(decoded,\n",
    "                      feed_dict={\n",
    "                          input: image,\n",
    "                          seq_len: seq_lengths,\n",
    "                          rnn_keep_prob: 1.0,\n",
    "                      })\n",
    "\n",
    "str_predictions = ctc_utils.sparse_tensor_to_strs(prediction)\n",
    "for w in str_predictions[0]:\n",
    "    print (int2word[w]),\n",
    "    print ('\\t'),\n",
    "\n",
    "# form string of detected musical notes\n",
    "SEMANTIC = ''\n",
    "for w in str_predictions[0]:\n",
    "    SEMANTIC += int2word[w] + '\\n'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # gets the audio file\n",
    "    audio = get_sinewave_audio(SEMANTIC)\n",
    "    # horizontally stacks the freqs    \n",
    "    audio =  np.hstack(audio)\n",
    "    # normalizes the freqs\n",
    "    audio *= 32767 / np.max(np.abs(audio))\n",
    "    #converts it to 16 bits\n",
    "    audio = audio.astype(np.int16)\n",
    "    #plays midi \n",
    "    play_obj = sa.play_buffer(audio, 1, 2, 44100)\n",
    "    #outputs to the console\n",
    "    if play_obj.is_playing():\n",
    "        print(\"\\nplaying...\")\n",
    "        print(f'\\n{SEMANTIC}')  \n",
    "    #stop playback when done\n",
    "    play_obj.wait_done()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREEZER METHOD V1\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "meta_path = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/semantic_model.meta' # Your .meta file\n",
    "eta_path = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/frozen_s.pb'\n",
    "    \n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(meta_path)\n",
    "saver.restore(sess,meta_path[:-5])\n",
    "graph = tf.get_default_graph()\n",
    "# fix nodes\n",
    "lines_list = open('C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/export_dir/test_nodes.txt').read().splitlines()\n",
    "output_node_names = lines_list\n",
    "#output_node_names = [n.name for n in tf.get_default_graph().as_graph_def().node]   # Output nodes    \n",
    "\n",
    "#with open('C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/export_dir/outputs.txt', 'w') as f:\n",
    "#    for item in output_node_names:\n",
    "#        f.write(\"%s\\n\" % item)\n",
    "\n",
    "output_graph_def = convert_variables_to_constants(sess, sess.graph_def, output_node_names)\n",
    "with tf.gfile.FastGFile(eta_path, mode='wb') as f:\n",
    "    f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATTEMPTS TO FIX MISSING INSTRUCTIONS\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from tensorflow.python.platform import gfile\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "eta_path = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/frozen.pb'\n",
    "beta_path = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/export_dir'\n",
    "# read graph definition\n",
    "f = gfile.FastGFile(eta_path, \"rb\")\n",
    "gd = graph_def = tf.GraphDef()\n",
    "graph_def.ParseFromString(f.read())\n",
    "\n",
    "# fix nodes\n",
    "for node in graph_def.node:\n",
    "    if node.op == 'RefSwitch':\n",
    "      node.op = 'Switch'\n",
    "      for index in xrange(len(node.input)):\n",
    "        if 'moving_' in node.input[index]:\n",
    "          node.input[index] = node.input[index] + '/read'\n",
    "    elif node.op == 'AssignSub':\n",
    "      node.op = 'Sub'\n",
    "      if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "    elif node.op == 'AssignAdd':\n",
    "      node.op = 'Add'\n",
    "      if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "    elif node.op == 'Assign':\n",
    "      node.op = 'Identity'\n",
    "      if 'use_locking' in node.attr: del node.attr['use_locking']\n",
    "      if 'validate_shape' in node.attr: del node.attr['validate_shape']\n",
    "      if len(node.input) == 2:\n",
    "        # input0: ref: Should be from a Variable node. May be uninitialized.\n",
    "        # input1: value: The value to be assigned to the variable.\n",
    "        node.input[0] = node.input[1]\n",
    "        del node.input[1]\n",
    "\n",
    "# import graph into session\n",
    "tf.import_graph_def(graph_def, name='')\n",
    "tf.train.write_graph(graph_def, './', 'good_frozen.pb', as_text=False)\n",
    "tf.train.write_graph(graph_def, './', 'good_frozen.pbtxt', as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRASH\n",
    "# Restore weights\n",
    "#with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n",
    "#    graph_def = tf.GraphDef()\n",
    "#    graph_def.ParseFromString(f.read())\n",
    "#\n",
    "#graph = tf.get_default_graph()\n",
    "#tf.import_graph_def(graph_def, name=\"prefix\")\n",
    "\n",
    "#saver = tf_v1.train.import_meta_graph(args.model)\n",
    "#saver.restore(sess,args.model[:-5])\n",
    "\n",
    "#sess.run(tf.initialize_all_variables())\n",
    "\n",
    "#graph = tf_v1.get_default_graph()\n",
    "\n",
    "#with tf_v1.gfile.GFile(eta_path, \"rb\") as f:\n",
    "#    graph_def = tf_v1.GraphDef()\n",
    "#    graph_def.ParseFromString(f.read())\n",
    "#    # import graph_def\n",
    "#with tf_v1.Graph().as_default() as graph:\n",
    "#    \n",
    "#    tf_v1.import_graph_def(graph_def, name='') \n",
    "#graph = tf_v1.get_default_graph()    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#with tf.Session(graph) as sess:\n",
    "#    file_writer = tf.summary.FileWriter(logdir='C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/export_dir', graph=g)\n",
    "\n",
    "#with tf_v1.gfile.FastGFile(eta_path,'rb') as f:\n",
    "#    graph_def = tf_v1.GraphDef()\n",
    "#    graph_def.ParseFromString(f.read())\n",
    "#    sess.graph.as_default()\n",
    "#    tf_v1.import_graph_def(graph_def, name='')\n",
    "#persisted_result = sess.graph.get_tensor_by_name(\"saved_result:0\")\n",
    "#tf.add_to_collection(tf.GraphKeys.VARIABLES,persisted_result)\n",
    "#try:\n",
    "    #saver = tf.train.Saver(tf.all_variables())\n",
    "#except:pass\n",
    "    #print(\"load data\")\n",
    "#saver.restore(sess, \"C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/semantic_model\")  # now OK\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
