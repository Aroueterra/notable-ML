{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE CODE\n",
    "# Saving \n",
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pbtxt')\n",
    "tf.train.write_graph(sess.graph_def, SAVED_MODEL_PATH , MODEL_NAME + '.pb',as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRAPH FREEZE utility\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "\n",
    "# Freeze the graph\n",
    "SAVED_MODEL_PATH=\"C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/\"\n",
    "MODEL_NAME=\"semantic_model\"\n",
    "# graph definition saved above\n",
    "input_graph = SAVED_MODEL_PATH+MODEL_NAME+'.meta'\n",
    "# any other saver to use other than default\n",
    "input_saver = \"\"\n",
    "# earlier definition file format text or binary\n",
    "input_binary = True\n",
    "# checkpoint file to merge with graph definition\n",
    "#input_checkpoint = SAVED_MODEL_PATH+MODEL_NAME+'.ckpt-'+str(TRAIN_STEPS)\n",
    "input_checkpoint = SAVED_MODEL_PATH+MODEL_NAME\n",
    "# output nodes inn our model\n",
    "#lines_list = open('C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/export_dir/test_nodes.txt').read().splitlines()\n",
    "#output_nodes = ','.join(lines_list)\n",
    "output_node_names = 'keep_prob,Reshape,seq_lengths,Mean,target,init'\n",
    "restore_op_name = 'save/restore_all'\n",
    "filename_tensor_name = 'save/Const:0'\n",
    "# output path\n",
    "output_graph = SAVED_MODEL_PATH+'frozen_'+MODEL_NAME+'.pb'\n",
    "# default True\n",
    "clear_devices = True\n",
    "initializer_nodes = \"\"\n",
    "variable_names_blacklist = \"\"\n",
    "\n",
    "freeze_graph.freeze_graph(\n",
    "    input_graph,\n",
    "    input_saver,\n",
    "    input_binary,\n",
    "    input_checkpoint,\n",
    "    output_node_names,\n",
    "    restore_op_name,\n",
    "    filename_tensor_name,\n",
    "    output_graph,\n",
    "    clear_devices,\n",
    "    initializer_nodes,\n",
    "    variable_names_blacklist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVED MODEL ATTEMPT\n",
    "Proj_NAME = 'semantic'\n",
    "MODEL_NAME = 'semantic_freeze'\n",
    "SAVED_MODEL_PATH = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/semantic_model'\n",
    "#CONS\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "out = saver.save(sess, SAVED_MODEL_PATH + MODEL_NAME + '.ckpt', global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict copy\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "#import tensorflow.compat.v1 as tf_v1\n",
    "import tensorflow.compat.v1 as tf_v1\n",
    "#To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
    "#tf.disable_eager_execution()\n",
    "tf_v1.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import ctc_utils\n",
    "\n",
    "import numpy as np\n",
    "tf_v1.disable_v2_behavior()\n",
    "Proj_NAME = 'semantic'\n",
    "MODEL_NAME = 'semantic_freeze'\n",
    "SAVED_MODEL_PATH = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/semantic_model.meta'\n",
    "SAVEPATH = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Big2'\n",
    "tf_v1.reset_default_graph()\n",
    "sess = tf_v1.Session()\n",
    "#SAVED_MODEL_PATH = 'C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/Models/semantic_model.meta'\n",
    "#saver = tf_v1.train.import_meta_graph(SAVED_MODEL_PATH)\n",
    "#saver.restore(sess,SAVED_MODEL_PATH[:-5])\n",
    "# Restore weights\n",
    "saver = tf_v1.train.import_meta_graph(SAVED_MODEL_PATH)\n",
    "#saver.restore(sess,SAVED_MODEL_PATH[:-5])\n",
    "#saver = tf_v1.train.Saver(tf_v1.global_variables())\n",
    "ckpt = tf_v1.train.get_checkpoint_state(SAVED_MODEL_PATH[:-19])\n",
    "saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "graph = tf_v1.get_default_graph()\n",
    "with tf.Session(graph=g) as sess:\n",
    "    file_writer = tf.summary.FileWriter(logdir='C:/Users/aroue/Downloads/Documents/@ML/MODELS/tf-end-to-end/export_dir', graph=g)\n",
    "#input = graph.get_tensor_by_name(\"model_input:0\")\n",
    "#seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
    "#rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "#height_tensor = graph.get_tensor_by_name(\"input_height:0\")\n",
    "#width_reduction_tensor = graph.get_tensor_by_name(\"width_reduction:0\")\n",
    "#logits = tf_v1.get_collection(\"logits\")[0]\n",
    "\n",
    "# Constants that are saved inside the model itself\n",
    "#WIDTH_REDUCTION, HEIGHT = sess.run([width_reduction_tensor, height_tensor])\n",
    "#decoded, _ = tf_v1.nn.ctc_greedy_decoder(logits, seq_len)\n",
    "\n",
    "#saver = tf_v1.train.Saver(max_to_keep=None)\n",
    "sess.run(tf_v1.global_variables_initializer())\n",
    "#save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
    "saver.save(sess,SAVEPATH+\"/model.ckpt\")\n",
    "\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
