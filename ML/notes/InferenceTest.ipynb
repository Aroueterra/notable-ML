{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test generated TFLITE\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\aroue\\Downloads\\Documents\\@ML\\notable-ML\\ML\\models\\semantic_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\aroue\\Downloads\\Documents\\@ML\\notable-ML\\ML\\models\\semantic_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x0000025DA6B960D0>]\n",
      "WARNING:tensorflow:Issue encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing model_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "C:\\Users\\aroue\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1480:0: error: 'tf.CTCLoss' op is neither a custom op nor a flex op\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1459:0: note: called from\n<ipython-input-8-31b4356d32c2>:10:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py:68:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2923:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2877:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py:536:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\n\ttf.CTCLoss {T = f32, ctc_merge_repeated = true, device = \"\", ignore_longer_outputs_than_inputs = false, preprocess_collapse_repeated = false}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\n\u001b[0m\u001b[0;32m    211\u001b[0m                                                  \u001b[0mtoco_flags_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\wrap_toco.py\u001b[0m in \u001b[0;36mwrapped_toco_convert\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m     31\u001b[0m   \u001b[1;34m\"\"\"Wraps TocoConvert with lazy loader.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m   return _pywrap_toco_api.TocoConvert(\n\u001b[0m\u001b[0;32m     33\u001b[0m       \u001b[0mmodel_flags_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: C:\\Users\\aroue\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1480:0: error: 'tf.CTCLoss' op is neither a custom op nor a flex op\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1459:0: note: called from\n<ipython-input-8-31b4356d32c2>:10:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py:68:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2923:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2877:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py:536:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\n\ttf.CTCLoss {T = f32, ctc_merge_repeated = true, device = \"\", ignore_longer_outputs_than_inputs = false, preprocess_collapse_repeated = false}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-31b4356d32c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                                        tf.lite.OpsSet.SELECT_TF_OPS]\n\u001b[0;32m     32\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_new_converter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\aroue\\Downloads\\Documents\\@ML\\notable-ML\\ML\\models\\converted_model.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Convert to TF Lite format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1945\u001b[0m         \u001b[1;32mNone\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdimension\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m     \"\"\"\n\u001b[1;32m-> 1947\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;31m# Converts model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_valid_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1300\u001b[1;33m       result = _toco_convert_impl(\n\u001b[0m\u001b[0;32m   1301\u001b[0m           \u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimized_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m       input_tensors, output_tensors, *args, **kwargs)\n\u001b[0;32m    607\u001b[0m   \u001b[0mdebug_info_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdebug_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdebug_info\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m   data = toco_convert_protos(\n\u001b[0m\u001b[0;32m    609\u001b[0m       \u001b[0mmodel_flags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[0mtoco_flags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    214\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_executable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_toco_from_proto_bin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: C:\\Users\\aroue\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1480:0: error: 'tf.CTCLoss' op is neither a custom op nor a flex op\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1459:0: note: called from\n<ipython-input-8-31b4356d32c2>:10:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py:68:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2923:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2877:0: note: called from\nC:\\Users\\aroue\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py:536:0: note: called from\n<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):\n\ttf.CTCLoss {T = f32, ctc_merge_repeated = true, device = \"\", ignore_longer_outputs_than_inputs = false, preprocess_collapse_repeated = false}\n"
     ]
    }
   ],
   "source": [
    "#Inference from sess\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "str = r\"C:\\Users\\aroue\\Downloads\\Documents\\@ML\\notable-ML\\ML\\models\\semantic_model.meta\"\n",
    "# Restore weights\n",
    "saver = tf.train.import_meta_graph(r\"C:\\Users\\aroue\\Downloads\\Documents\\@ML\\notable-ML\\ML\\models\\semantic_model.meta\")\n",
    "saver.restore(sess,str[:-5])\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "input = graph.get_tensor_by_name(\"model_input:0\")\n",
    "Mean = graph.get_tensor_by_name(\"Mean:0\")\n",
    "#seq_len = graph.get_tensor_by_name(\"seq_lengths:0\")\n",
    "#rnn_keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "greed = graph.get_tensor_by_name(\"CTCGreedyDecoder:0\")\n",
    "#logits = graph.get_tensor_by_name(\"fully_connected/BiasAdd:0\")\n",
    "output, _ = tf.nn.ctc_greedy_decoder(logits, seq_len) \n",
    "type(output)\n",
    "print(output)\n",
    "#out = tf.identity(output, name=\"out\")\n",
    "#img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n",
    "#const = tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n",
    "#val = img + const\n",
    "#out = tf.identity(val, name=\"out\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_session(sess, [input], [Mean,greed])\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "                                       tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "converter.experimental_new_converter = True\n",
    "tflite_model = converter.convert()\n",
    "open(r\"C:\\Users\\aroue\\Downloads\\Documents\\@ML\\notable-ML\\ML\\models\\converted_model.tflite\", \"wb\").write(tflite_model)\n",
    "# Convert to TF Lite format\n",
    "#with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "print(\"==========\")\n",
    "# Continue to get tensors and so forth, as shown above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\n",
    "  graph_def_file, input_arrays, output_arrays)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
